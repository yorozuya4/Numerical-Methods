{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VJi_3Vb-QPja"
      },
      "source": [
        "#### You just fill in the blank spaces (where it says code). You don't need to touch the other parts.\n",
        "\n",
        "### You should submit an ipynb file with the output: \"Project_{id}_{name}.ipynb\"\n",
        "### ðŸ“§If you have any question, you can ask by e-mail: sisifhro@kaist.ac.kr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 225,
      "metadata": {
        "id": "oS87GSKRQPKD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80dad7ef-2da4-40c2-df89-d8d374730f48"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "E: Unable to locate package python-rdkit\n",
            "Requirement already satisfied: rdkit in /usr/local/lib/python3.10/dist-packages (2023.9.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rdkit) (1.23.5)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from rdkit) (9.4.0)\n"
          ]
        }
      ],
      "source": [
        "#@title Install rdkit\n",
        "!apt-get install -y python-rdkit librdkit1 rdkit-data\n",
        "!pip install rdkit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 226,
      "metadata": {
        "id": "xHEnKhLxSAyV"
      },
      "outputs": [],
      "source": [
        "#@title Import package\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "\n",
        "import copy\n",
        "import csv\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem.rdMolDescriptors import GetMorganFingerprintAsBitVect\n",
        "\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NpENhddcjuqB"
      },
      "source": [
        "### ClinTox Dataset\n",
        "We will classify ClinTox dataset which compares drugs approved by the FDA and drugs that have failed clinical trials for toxicity reasons.\n",
        "You can download this datset with the code below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 227,
      "metadata": {
        "id": "zvn94N1Bl9PZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d2bb557-68a6-4336-bc63-2aea6ee2ea81"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'clintox' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "'''\n",
        "The code for download ClinTox dataset. The folder 'clintox' would be generated.\n",
        "In the 'clintox; folder, the files of clintox_train.csv, clintox_valid.csv, clintox_test.csv would exist.\n",
        "'''\n",
        "!git clone https://huggingface.co/datasets/zpn/clintox"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 228,
      "metadata": {
        "id": "czeptB-ITej2"
      },
      "outputs": [],
      "source": [
        "#@title Load data\n",
        "'''\n",
        "In Practice 3, we separated the data into train, valid, and test through 'train_test_split'.\n",
        "However, since the downloaded data is already divided into train, valid, and, test you can just load each data.\n",
        "'''\n",
        "train_data = pd.read_csv('clintox/clintox_train.csv')\n",
        "valid_data = pd.read_csv('clintox/clintox_valid.csv')\n",
        "test_data = pd.read_csv('clintox/clintox_test.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n77b0wwhn6Sp"
      },
      "source": [
        "### 1. Extract ECFP\n",
        "\n",
        "Extract ECFP from clintox dataset. You should define 'get ECFP' function which  ECFP list for each smile."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 229,
      "metadata": {
        "id": "hMASkwH-n_rz"
      },
      "outputs": [],
      "source": [
        "def get_ecfp(smiles):\n",
        "    '''\n",
        "    input: (string) SMILES\n",
        "    output: (list) ECFP fingerprint list\n",
        "    '''\n",
        "    ################ Code ################\n",
        "    mol=Chem.MolFromSmiles(smiles)\n",
        "    ecfp=GetMorganFingerprintAsBitVect(mol,radius=2,nBits=1024)\n",
        "    ecfp_list=list(map(int,ecfp.ToBitString()))\n",
        "    return ecfp_list\n",
        "    ######################################"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 230,
      "metadata": {
        "id": "wM60ku36TjWi"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "In this section, you should specify variables (X_train, X_valid, X_test, y_train, y_valid, y_test)\n",
        "\n",
        "X_train, X_valid, X_test: (list) all ECFP fingerprint list for all SMILES\n",
        "y_train, y_valid, y_test = (list) all target value (0 or 1) list for all SMILES\n",
        "'''\n",
        "################ Code ################\n",
        "X_train=list()\n",
        "for smiles in train_data['smiles']:\n",
        "    X_train.append(get_ecfp(smiles))\n",
        "\n",
        "X_valid=list()\n",
        "for smiles in valid_data['smiles']:\n",
        "    X_valid.append(get_ecfp(smiles))\n",
        "\n",
        "X_test=list()\n",
        "for smiles in test_data['smiles']:\n",
        "    X_test.append(get_ecfp(smiles))\n",
        "\n",
        "y_train=train_data['target'].tolist()\n",
        "y_valid=valid_data['target'].tolist()\n",
        "y_test=test_data['target'].tolist()\n",
        "######################################"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eD0DQJBPT57b"
      },
      "source": [
        "### 2. Machine Learning model\n",
        "\n",
        "You should construct 2 classification model (SVM and RF) to predict whether the drugs are toxic (0 of 1). You can train the model from the ECFP. You will get full credit if you get accuracy of test dataset above 0.92 for each model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 231,
      "metadata": {
        "id": "b5wCovOxT3MX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "31de2279-558c-44cd-a9a5-19d234e89c3c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(kernel='linear', random_state=1)"
            ],
            "text/html": [
              "<style>#sk-container-id-25 {color: black;background-color: white;}#sk-container-id-25 pre{padding: 0;}#sk-container-id-25 div.sk-toggleable {background-color: white;}#sk-container-id-25 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-25 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-25 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-25 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-25 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-25 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-25 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-25 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-25 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-25 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-25 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-25 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-25 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-25 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-25 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-25 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-25 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-25 div.sk-item {position: relative;z-index: 1;}#sk-container-id-25 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-25 div.sk-item::before, #sk-container-id-25 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-25 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-25 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-25 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-25 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-25 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-25 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-25 div.sk-label-container {text-align: center;}#sk-container-id-25 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-25 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-25\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(kernel=&#x27;linear&#x27;, random_state=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-25\" type=\"checkbox\" checked><label for=\"sk-estimator-id-25\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(kernel=&#x27;linear&#x27;, random_state=1)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 231
        }
      ],
      "source": [
        "# SVC\n",
        "################ Code ################\n",
        "from sklearn.svm import SVC\n",
        "svm=SVC(kernel='linear',C=1.0,random_state=1)\n",
        "svm.fit(X_train, y_train)\n",
        "######################################"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 232,
      "metadata": {
        "id": "C-mgXLTsUUr2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9dafed88-1a9c-4c80-b9de-83c67f0dbf8c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9805249788314987\n",
            "0.9256756756756757\n"
          ]
        }
      ],
      "source": [
        "print(svm.score(X_train, y_train))\n",
        "print(svm.score(X_test, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 233,
      "metadata": {
        "id": "iGQnHS_MUYtC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "0cc1d834-e41d-43f1-8ede-7ceb06641c73"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(random_state=1)"
            ],
            "text/html": [
              "<style>#sk-container-id-26 {color: black;background-color: white;}#sk-container-id-26 pre{padding: 0;}#sk-container-id-26 div.sk-toggleable {background-color: white;}#sk-container-id-26 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-26 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-26 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-26 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-26 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-26 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-26 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-26 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-26 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-26 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-26 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-26 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-26 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-26 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-26 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-26 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-26 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-26 div.sk-item {position: relative;z-index: 1;}#sk-container-id-26 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-26 div.sk-item::before, #sk-container-id-26 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-26 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-26 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-26 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-26 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-26 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-26 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-26 div.sk-label-container {text-align: center;}#sk-container-id-26 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-26 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-26\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(random_state=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-26\" type=\"checkbox\" checked><label for=\"sk-estimator-id-26\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=1)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 233
        }
      ],
      "source": [
        "# RF\n",
        "################ Code ################\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "rf = RandomForestClassifier(n_estimators=100,random_state=1)\n",
        "rf.fit(X_train, y_train)\n",
        "######################################"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 234,
      "metadata": {
        "id": "Xu2xID0vUhzE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "689958e2-b6cd-492b-cd0f-0d203eb09631"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9822184589331076\n",
            "0.9324324324324325\n"
          ]
        }
      ],
      "source": [
        "print(rf.score(X_train,y_train))\n",
        "print(rf.score(X_test,y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "airzNCL7UsMG"
      },
      "source": [
        "### 3. Pytorch Regression\n",
        "\n",
        "You should construct classification for classifying whether the drugs are toxic (0 or 1). You should use 3 linear layers and ReLU activation layers. You can modify learning rate, batch size, and num_epochs, and hidden dimension. You will get full credit if you get accuracy of dataset above 0.92 for the model and satisfy above condition."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 235,
      "metadata": {
        "id": "zGatFG7zSgpD"
      },
      "outputs": [],
      "source": [
        "#@title Define Dataset\n",
        "\n",
        "class SMILESDataset(Dataset):\n",
        "    def __init__(self, data):\n",
        "        '''\n",
        "        input : dataframe\n",
        "\n",
        "        You can specify self.X, self.y\n",
        "        self.X: An array that extracted ECFP for all smiles\n",
        "        self.y: An array of target values for all smiles\n",
        "        '''\n",
        "\n",
        "        ################ Code ################\n",
        "        self.data=data\n",
        "        ecfp_vectors=list()\n",
        "        for smiles in data['smiles']:\n",
        "            ecfp=get_ecfp(smiles)\n",
        "            ecfp_vectors.append(ecfp)\n",
        "        self.X=torch.tensor(ecfp_vectors)\n",
        "        self.y=torch.tensor(data['target'].values)\n",
        "        ######################################\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.y)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        data_dict = dict()\n",
        "        data_dict['X'] = self.X[idx]\n",
        "        data_dict['y'] = self.y[idx]\n",
        "        return data_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 236,
      "metadata": {
        "id": "k0b9eeMPWJ0U"
      },
      "outputs": [],
      "source": [
        "train_dataset = SMILESDataset(train_data)\n",
        "valid_dataset = SMILESDataset(valid_data)\n",
        "test_dataset = SMILESDataset(test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 237,
      "metadata": {
        "id": "aMDBnAWHTQdp"
      },
      "outputs": [],
      "source": [
        "#@title Define Dataloader\n",
        "'''\n",
        "You can modify batch_size.\n",
        "'''\n",
        "################ Code ################\n",
        "batch_size=64\n",
        "######################################\n",
        "\n",
        "train_data_loader = DataLoader(dataset = train_dataset, batch_size = batch_size, shuffle = True)\n",
        "val_data_loader = DataLoader(dataset = valid_dataset, batch_size = batch_size, shuffle = False)\n",
        "test_data_loader = DataLoader(dataset = test_dataset, batch_size = batch_size, shuffle = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 238,
      "metadata": {
        "id": "i73xAK0yVzBH"
      },
      "outputs": [],
      "source": [
        "#@title Define Model (Classifier)\n",
        "class Classifier(nn.Module):\n",
        "################ Code ################\n",
        "    def __init__(self,in_dim,hid_dim,out_dim):\n",
        "        super(Classifier,self).__init__()\n",
        "        self.linear1=nn.Linear(in_dim,hid_dim)\n",
        "        self.linear2=nn.Linear(hid_dim,hid_dim)\n",
        "        self.linear3=nn.Linear(hid_dim,out_dim)\n",
        "        self.relu=nn.ReLU()\n",
        "\n",
        "    def forward(self,x):\n",
        "        x =self.relu(self.linear1(x))\n",
        "        x=self.relu(self.linear2(x))\n",
        "        x=self.linear3(x)\n",
        "        return x\n",
        "    ######################################"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 239,
      "metadata": {
        "id": "pN3kfhuSWsmL"
      },
      "outputs": [],
      "source": [
        "#@title Define Hyperparameters\n",
        "'''\n",
        "You should set hyperparameters. you can modify the learning rate and hidden dimensions.\n",
        "\n",
        "'''\n",
        "################ Code ################\n",
        "in_dim=1024\n",
        "hid_dim=512\n",
        "out_dim=2\n",
        "lr=1e-3\n",
        "num_epoch=100\n",
        "######################################"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 240,
      "metadata": {
        "id": "CFHk11geXjYY"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "You should specify model.\n",
        "\n",
        "'''\n",
        "################ Code ################\n",
        "model=Classifier(in_dim=in_dim,hid_dim=hid_dim,out_dim=out_dim)\n",
        "######################################\n",
        "crossentropy_loss = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 241,
      "metadata": {
        "id": "sqY9XI_wXkiB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "outputId": "cdbdef5b-9c64-4ae7-c09c-436b77a2e28f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------- 100 times train and test START! ----------\n",
            "Model name: \t\tClassifier\n",
            "\n",
            "\n",
            "epoch: 10 / 100 epoch \t loss: 0.0008\n",
            "epoch: 20 / 100 epoch \t loss: 0.0004\n",
            "epoch: 30 / 100 epoch \t loss: 0.0004\n",
            "epoch: 40 / 100 epoch \t loss: 0.0005\n",
            "epoch: 50 / 100 epoch \t loss: 0.0004\n",
            "epoch: 60 / 100 epoch \t loss: 0.0004\n",
            "epoch: 70 / 100 epoch \t loss: 0.0004\n",
            "epoch: 80 / 100 epoch \t loss: 0.0004\n",
            "epoch: 90 / 100 epoch \t loss: 0.0005\n",
            "epoch: 100 / 100 epoch \t loss: 0.0004\n",
            "\n",
            "---------- TRAIN RESULTS ----------\n",
            "Best epoch \t: 89\n",
            "Best loss \t: 0.0004\n",
            "\n",
            "---------- VALIDATION RESULTS ----------\n",
            "Best epoch \t: 2\n",
            "Best loss \t: 0.0046\n"
          ]
        }
      ],
      "source": [
        "#@title Train\n",
        "torch.manual_seed(0)\n",
        "torch.cuda.manual_seed_all(0)\n",
        "\n",
        "\n",
        "num_train_data = len(train_dataset)\n",
        "num_val_data = len(valid_dataset)\n",
        "\n",
        "train_loss_history = []\n",
        "val_loss_history = []\n",
        "\n",
        "best_train_loss = 99999999\n",
        "best_val_loss = 99999999\n",
        "\n",
        "print(f\"---------- {num_epoch} times train and test START! ----------\")\n",
        "print(f\"Model name: \\t\\t{type(model).__name__}\")\n",
        "print()\n",
        "print()\n",
        "\n",
        "\n",
        "# model.cuda()   # Turn on when you want to use GPU\n",
        "start_time = time.time()\n",
        "for epoch in range(1, num_epoch+1):\n",
        "\n",
        "    # Train\n",
        "    model.train()\n",
        "    train_loss = []\n",
        "    for i, data in enumerate(train_data_loader):\n",
        "        x = data['X'].float()\n",
        "        label_true = data['y'].long()\n",
        "        # x = x.cuda()  # Turn on when you want to use GPU\n",
        "        # label_true = label_true.cuda()  # Turn on when you want to use GPU\n",
        "        optimizer.zero_grad()\n",
        "        label_pred = model(x)\n",
        "\n",
        "        loss = crossentropy_loss(label_pred, label_true)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        loss = copy.deepcopy(loss.data.cpu().numpy())\n",
        "        train_loss.append(loss)\n",
        "    train_mean_loss = np.sum(train_loss)/num_train_data\n",
        "    train_loss_history.append(train_mean_loss)\n",
        "\n",
        "    if best_train_loss > train_mean_loss:\n",
        "        best_train_epoch = epoch\n",
        "        best_train_loss = train_mean_loss\n",
        "        best_train_model = copy.deepcopy(model.state_dict())\n",
        "\n",
        "    if epoch == 0:\n",
        "        print(f\"epoch time: {time.time()-start_time:.2f}\")\n",
        "\n",
        "    if epoch % 10 == 0 or epoch == num_epoch:\n",
        "            print(f\"epoch: {epoch} / {num_epoch} epoch \\t loss: {train_mean_loss:.4f}\")\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    val_loss = []\n",
        "    with torch.no_grad():\n",
        "        for i, data in enumerate(val_data_loader):\n",
        "            x = data['X'].float()\n",
        "            label_true = data['y'].long()\n",
        "            # x = x.cuda()  # Turn on when you want to use GPU\n",
        "            # label_true = label_true.cuda()  # Turn on when you want to use GPU\n",
        "\n",
        "            label_pred = model(x)\n",
        "\n",
        "            loss = crossentropy_loss(label_pred, label_true)\n",
        "\n",
        "            loss = copy.deepcopy(loss.data.cpu().numpy())\n",
        "            val_loss.append(loss)\n",
        "        val_mean_loss = np.sum(val_loss)/num_val_data\n",
        "        val_loss_history.append(val_mean_loss)\n",
        "\n",
        "\n",
        "        if best_val_loss > val_mean_loss:\n",
        "            best_val_epoch = epoch + 1\n",
        "            best_val_loss = val_mean_loss\n",
        "            best_val_model = copy.deepcopy(model.state_dict())\n",
        "\n",
        "            torch.save({\n",
        "                'epoch': epoch,\n",
        "                'model_state_dict': model.state_dict(),\n",
        "                'optimizer_state_dict': optimizer.state_dict(),\n",
        "                'loss': loss,\n",
        "\n",
        "            }, 'best_model.ckpt')\n",
        "\n",
        "print()\n",
        "print(\"---------- TRAIN RESULTS ----------\")\n",
        "print(f\"Best epoch \\t: {best_train_epoch}\")\n",
        "print(f\"Best loss \\t: {best_train_loss:.4f}\")\n",
        "print()\n",
        "\n",
        "print(\"---------- VALIDATION RESULTS ----------\")\n",
        "print(f\"Best epoch \\t: {best_val_epoch}\")\n",
        "print(f\"Best loss \\t: {best_val_loss:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 242,
      "metadata": {
        "id": "cfaiLMSHgnge",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "outputId": "35b9a299-92b5-4603-fe31-3e8c7bf5114b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy: 0.9391891891891891 \n"
          ]
        }
      ],
      "source": [
        "#@title Test\n",
        "# checkpoint = torch.load('best_model.ckpt')\n",
        "# model = Classifier(('you should write parameters'))\n",
        "# optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "# model.load_state_dict(checkpoint['model_state_dict'])\n",
        "# optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "\n",
        "\n",
        "model.eval()\n",
        "test_loss, pred_list, label_list = [], [], []\n",
        "with torch.no_grad():\n",
        "    for i, data in enumerate(test_data_loader):\n",
        "        x = data['X'].float()\n",
        "        label_true = data['y'].long()\n",
        "        # x = x.cuda()  # Turn on when you want to use GPU\n",
        "        # label_true = label_true.cuda()  # Turn on when you want to use GPU\n",
        "\n",
        "        label_pred = model(x)\n",
        "        _,pred = label_pred.cpu().topk(1,dim=1)\n",
        "        pred = pred.reshape(-1)\n",
        "\n",
        "        pred_list.append(pred)\n",
        "        label_list.append(label_true)\n",
        "\n",
        "        loss = crossentropy_loss(label_pred, label_true)\n",
        "\n",
        "        loss = copy.deepcopy(loss.data.cpu().numpy())\n",
        "        test_loss.append(loss)\n",
        "\n",
        "all_pred_list = torch.concat(pred_list)\n",
        "all_label_list = torch.concat(label_list)\n",
        "print(f'accuracy: {accuracy_score(all_label_list, all_pred_list)} ')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 242,
      "metadata": {
        "id": "Tub6nkqlaI2y"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}